"""Search handler with AI context understanding"""
import requests
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes, CallbackQueryHandler
import sys
from pathlib import Path
import json

# Add parent directory to path
sys.path.append(str(Path(__file__).parent.parent))

import config
from context_analyzer import get_context_analyzer


async def search_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle /search command"""
    if not context.args:
        await update.message.reply_text(
            "–£–∫–∞–∂–∏—Ç–µ –º–∞—Ä–∫—É —Å—Ç–∞–ª–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞.\n–ü—Ä–∏–º–µ—Ä: `/search 420`",
            parse_mode='Markdown'
        )
        return

    grade_name = ' '.join(context.args)
    await perform_search(update, grade_name, context)


async def handle_text_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle direct text messages with automatic intent recognition"""
    message_text = update.message.text.strip()

    # Ignore very short or long messages
    if len(message_text) < 2 or len(message_text) > 100:
        return

    # Analyze intent using GPT-4 mini
    analyzer = get_context_analyzer()
    analysis = analyzer.analyze_message(message_text)

    intent = analysis.get('intent', 'search')
    grade = analysis.get('grade')

    # Route to appropriate handler based on intent
    if intent == 'stats':
        # Import stats handler
        from . import stats
        await stats.stats_command(update, context)
        return

    elif intent == 'help':
        # Import help handler
        from . import help_command
        await help_command.help_command(update, context)
        return

    elif intent == 'analogues' and grade:
        # Import analogues handler
        from . import analogues
        # Manually set args for analogues command
        context.args = [grade]
        await analogues.analogues_command(update, context)
        return

    elif intent == 'fuzzy_search' and grade:
        # Import fuzzy_search handler
        from . import fuzzy_search
        # Manually set args for fuzzy_search command
        tolerance = analysis.get('tolerance') or 50
        max_results = analysis.get('max_results') or 1
        context.args = [grade, str(tolerance), str(max_results)]
        await fuzzy_search.fuzzy_search_command(update, context)
        return

    # Default: search
    # Use extracted grade or original message
    search_query = grade if grade else message_text
    await perform_search(update, search_query, context)


async def perform_search(update: Update, grade_name: str, context: ContextTypes.DEFAULT_TYPE = None, force_ai: bool = False):
    """Perform steel grade search with AI confirmation logic"""
    try:
        # Initialize user_data if needed
        if context and 'search_attempts' not in context.user_data:
            context.user_data['search_attempts'] = {}

        # Get normalized grade name for tracking attempts
        normalized_grade = grade_name.strip().upper()

        # Get attempt count for this grade
        attempt_count = 0
        if context:
            attempt_count = context.user_data['search_attempts'].get(normalized_grade, 0)

        # Send "searching" message
        status_msg = await update.message.reply_text(
            f"üîç –ò—â—É –º–∞—Ä–∫—É `{grade_name}`...\n\n"
            f"‚ñ™Ô∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (10,394 –º–∞—Ä–æ–∫)\n\n"
            f"‚è≥ –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...",
            parse_mode='Markdown'
        )

        # Make API request WITHOUT AI fallback (search only in DB)
        # unless force_ai is True
        response = requests.get(
            config.SEARCH_ENDPOINT,
            params={
                'grade': grade_name,
                'ai': 'true' if force_ai else 'false'  # AI only if forced
            },
            timeout=60
        )

        if response.status_code != 200:
            await status_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {response.status_code}"
            )
            return

        results = response.json()

        # Delete "searching" message
        await status_msg.delete()

        if not results:
            # Not found in database - handle based on attempt count
            if context:
                # Increment attempt count
                attempt_count += 1
                context.user_data['search_attempts'][normalized_grade] = attempt_count

            if attempt_count == 1:
                # First attempt - suggest checking spelling
                await update.message.reply_text(
                    f"‚ùå **–ú–∞—Ä–∫–∞ `{grade_name}` –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö**\n\n"
                    f"üìã **–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ø–∏—Å–∞–Ω–∏–µ –º–∞—Ä–∫–∏ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑:**\n"
                    f"‚Ä¢ –í–æ–∑–º–æ–∂–Ω–æ, –æ–ø–µ—á–∞—Ç–∫–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏\n"
                    f"‚Ä¢ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤ (–®–•15 –≤–º–µ—Å—Ç–æ –®–• 15)\n"
                    f"‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–≥–∏—Å—Ç—Ä (AISI 420 –≤–º–µ—Å—Ç–æ aisi 420)\n"
                    f"‚Ä¢ –£—Ç–æ—á–Ω–∏—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—è –∏–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç\n\n"
                    f"üí° –ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞—Ä–∫–∏.",
                    parse_mode='Markdown'
                )
                return

            elif attempt_count == 2:
                # Second attempt - offer AI search confirmation
                keyboard = [
                    [
                        InlineKeyboardButton("‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å AI Search", callback_data=f'confirm_ai:{grade_name}'),
                    ],
                    [
                        InlineKeyboardButton("‚úèÔ∏è –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –µ—â–µ —Ä–∞–∑", callback_data=f'retry_search:{grade_name}')
                    ]
                ]
                reply_markup = InlineKeyboardMarkup(keyboard)

                await update.message.reply_text(
                    f"‚ùå **–ú–∞—Ä–∫–∞ `{grade_name}` —Å–Ω–æ–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö**\n\n"
                    f"ü§î **–ß—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ?**\n\n"
                    f"**–í–∞—Ä–∏–∞–Ω—Ç 1:** –ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –ø–æ–∏—Å–∫ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ (Perplexity AI)\n"
                    f"  ‚Ä¢ –ó–∞–π–º–µ—Ç 20-30 —Å–µ–∫—É–Ω–¥\n"
                    f"  ‚Ä¢ –î–∞–Ω–Ω—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–º–∏\n"
                    f"  ‚Ä¢ –¢—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Å—Å—ã–ª–∫–µ\n\n"
                    f"**–í–∞—Ä–∏–∞–Ω—Ç 2:** –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –µ—â–µ —Ä–∞–∑ —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ\n"
                    f"  ‚Ä¢ –ü–æ–∏—Å–∫ –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö\n\n"
                    f"–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:",
                    parse_mode='Markdown',
                    reply_markup=reply_markup
                )
                return

            else:
                # Third+ attempt - automatic AI search
                await update.message.reply_text(
                    f"üîç –ú–∞—Ä–∫–∞ `{grade_name}` –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.\n\n"
                    f"ü§ñ **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Perplexity AI...**\n\n"
                    f"‚è≥ –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ 20-30 —Å–µ–∫...",
                    parse_mode='Markdown'
                )

                # Perform AI search
                await perform_ai_search(update, grade_name, context)
                return

        else:
            # Found in database - reset attempt counter
            if context and normalized_grade in context.user_data.get('search_attempts', {}):
                del context.user_data['search_attempts'][normalized_grade]

            # Format and send results
            for i, result in enumerate(results[:config.MAX_RESULTS_PER_MESSAGE], 1):
                message = format_steel_result(result, i, len(results))
                await update.message.reply_text(message, parse_mode='Markdown')

            # If more results exist
            if len(results) > config.MAX_RESULTS_PER_MESSAGE:
                await update.message.reply_text(
                    f"‚ö†Ô∏è –ü–æ–∫–∞–∑–∞–Ω—ã –ø–µ—Ä–≤—ã–µ {config.MAX_RESULTS_PER_MESSAGE} –∏–∑ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."
                )

    except requests.exceptions.Timeout:
        await update.message.reply_text(
            "‚è±Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ–∏—Å–∫–∞.\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
        )
    except Exception as e:
        await update.message.reply_text(
            f"‚ùå –û—à–∏–±–∫–∞: {str(e)}"
        )


async def perform_ai_search(update: Update, grade_name: str, context: ContextTypes.DEFAULT_TYPE = None):
    """Perform AI search with Perplexity"""
    try:
        status_msg = await update.message.reply_text(
            f"ü§ñ –ò—â—É –º–∞—Ä–∫—É `{grade_name}` —á–µ—Ä–µ–∑ Perplexity AI...\n\n"
            f"‚è≥ –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ 20-30 —Å–µ–∫...",
            parse_mode='Markdown'
        )

        # Make API request with AI enabled
        response = requests.get(
            config.SEARCH_ENDPOINT,
            params={
                'grade': grade_name,
                'ai': 'true'
            },
            timeout=60
        )

        if response.status_code != 200:
            await status_msg.edit_text(
                f"‚ùå –û—à–∏–±–∫–∞ AI –ø–æ–∏—Å–∫–∞: {response.status_code}"
            )
            return

        results = response.json()

        # Delete status message
        await status_msg.delete()

        if not results:
            await update.message.reply_text(
                f"‚ùå **–ú–∞—Ä–∫–∞ `{grade_name}` –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –¥–∞–∂–µ —á–µ—Ä–µ–∑ AI Search**\n\n"
                f"–ü–æ–∏—Å–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω:\n"
                f"‚Ä¢ ‚úì –í –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (10,394 –º–∞—Ä–æ–∫)\n"
                f"‚Ä¢ ‚úì –ß–µ—Ä–µ–∑ Perplexity AI (–∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–ø–æ–∏—Å–∫)\n"
                f"‚Ä¢ ‚úì –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö\n\n"
                f"**–†–µ–∑—É–ª—å—Ç–∞—Ç:** –•–∏–º–∏—á–µ—Å–∫–∏–π —Å–æ—Å—Ç–∞–≤ –∏ –∞–Ω–∞–ª–æ–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.\n\n"
                f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n"
                f"‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ø–∏—Å–∞–Ω–∏–µ –º–∞—Ä–∫–∏\n"
                f"‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏–µ\n"
                f"‚Ä¢ –£—Ç–æ—á–Ω–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—è –∏–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç",
                parse_mode='Markdown'
            )
            return

        # Reset attempt counter after successful AI search
        if context:
            normalized_grade = grade_name.strip().upper()
            if normalized_grade in context.user_data.get('search_attempts', {}):
                del context.user_data['search_attempts'][normalized_grade]

        # Format and send results
        for i, result in enumerate(results[:config.MAX_RESULTS_PER_MESSAGE], 1):
            message = format_steel_result(result, i, len(results))
            await update.message.reply_text(message, parse_mode='Markdown')

        # If more results exist
        if len(results) > config.MAX_RESULTS_PER_MESSAGE:
            await update.message.reply_text(
                f"‚ö†Ô∏è –ü–æ–∫–∞–∑–∞–Ω—ã –ø–µ—Ä–≤—ã–µ {config.MAX_RESULTS_PER_MESSAGE} –∏–∑ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."
            )

    except requests.exceptions.Timeout:
        await update.message.reply_text(
            "‚è±Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è AI –ø–æ–∏—Å–∫–∞.\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
        )
    except Exception as e:
        await update.message.reply_text(
            f"‚ùå –û—à–∏–±–∫–∞ AI –ø–æ–∏—Å–∫–∞: {str(e)}"
        )


def format_steel_result(result: dict, index: int = 1, total: int = 1) -> str:
    """Format steel grade result for display"""
    # Header
    grade = result.get('grade', 'N/A')
    is_ai = result.get('id') == 'AI'

    header = f"üîß **–ú–∞—Ä–∫–∞: {grade}**"
    if is_ai:
        ai_source = result.get('ai_source', 'ai').upper()
        header += f" ü§ñ ({ai_source})"
    if total > 1:
        header += f" ({index}/{total})"

    # Basic info
    lines = [header, ""]

    # Validation warning (if failed)
    if is_ai and not result.get('validated', True):
        lines.append("‚ö†Ô∏è **–í–ù–ò–ú–ê–ù–ò–ï:** –î–∞–Ω–Ω—ã–µ –Ω–µ –ø—Ä–æ—à–ª–∏ –ø–æ–ª–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é")
        lines.append("")

    # Standard and manufacturer
    standard = result.get('standard')
    manufacturer = result.get('manufacturer')

    if standard:
        lines.append(f"üìã **–°—Ç–∞–Ω–¥–∞—Ä—Ç:** {standard}")
    if manufacturer:
        lines.append(f"üè≠ **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å:** {manufacturer}")

    # Chemical composition
    lines.append("\n**–•–∏–º–∏—á–µ—Å–∫–∏–π —Å–æ—Å—Ç–∞–≤:**")

    elements = {
        'C': '–£–≥–ª–µ—Ä–æ–¥',
        'Cr': '–•—Ä–æ–º',
        'Ni': '–ù–∏–∫–µ–ª—å',
        'Mo': '–ú–æ–ª–∏–±–¥–µ–Ω',
        'V': '–í–∞–Ω–∞–¥–∏–π',
        'W': '–í–æ–ª—å—Ñ—Ä–∞–º',
        'Co': '–ö–æ–±–∞–ª—å—Ç',
        'Mn': '–ú–∞—Ä–≥–∞–Ω–µ—Ü',
        'Si': '–ö—Ä–µ–º–Ω–∏–π',
        'Cu': '–ú–µ–¥—å',
        'Nb': '–ù–∏–æ–±–∏–π',
        'N': '–ê–∑–æ—Ç'
    }

    composition_found = False
    for symbol, name in elements.items():
        value = result.get(symbol.lower())
        if value and value not in ['0', '0.00', None, 'null']:
            lines.append(f"  ‚Ä¢ {symbol}: {value}%")
            composition_found = True

    if not composition_found:
        lines.append("  _–•–∏–º–∏—á–µ—Å–∫–∏–π —Å–æ—Å—Ç–∞–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω_")

    # Analogues
    analogues = result.get('analogues')
    if analogues:
        # Check for "not found" messages
        if '–Ω–µ –Ω–∞–π–¥–µ–Ω' in str(analogues).lower() or '—É–Ω–∏–∫–∞–ª—å–Ω–∞—è' in str(analogues).lower():
            lines.append(f"\nüîó **–ê–Ω–∞–ª–æ–≥–∏:** _–ê–Ω–∞–ª–æ–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã (—É–Ω–∏–∫–∞–ª—å–Ω–∞—è –º–∞—Ä–∫–∞)_")
        elif analogues not in [None, '', 'N/A', 'null']:
            lines.append(f"\nüîó **–ê–Ω–∞–ª–æ–≥–∏:** {analogues}")

    # Application (if available from AI)
    application = result.get('application')
    if application and application not in ['null', None, '']:
        lines.append(f"\nüí° **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:**\n_{application}_")

    # Properties (if available from AI)
    properties = result.get('properties')
    if properties and properties not in ['null', None, '']:
        lines.append(f"\n‚öôÔ∏è **–°–≤–æ–π—Å—Ç–≤–∞:**\n_{properties}_")

    # Source information and link
    source_url = result.get('link') or result.get('source_url')

    if is_ai:
        ai_src = result.get('ai_source', 'AI')
        lines.append(f"\nüåê **–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö:** {ai_src.upper()}")

        # Show if from PDF
        if result.get('pdf_extracted'):
            pdf_url = result.get('pdf_source', 'PDF datasheet')
            lines.append(f"üìÑ –î–∞–Ω–Ω—ã–µ –∏–∑–≤–ª–µ—á–µ–Ω—ã –∏–∑ PDF —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏")

        # Show validation status
        if result.get('validated', True):
            lines.append("‚úÖ –î–∞–Ω–Ω—ã–µ –ø—Ä–æ—à–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é")
        else:
            lines.append("‚ö†Ô∏è –î–∞–Ω–Ω—ã–µ —Ç—Ä–µ–±—É—é—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏")

        # CRITICAL WARNING about AI data accuracy
        lines.append("\n‚ö†Ô∏è **–í–ê–ñ–ù–û:** –î–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã —á–µ—Ä–µ–∑ –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å")
        lines.append("‚Ä¢ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω–æ–π –∏–ª–∏ –Ω–µ–ø–æ–ª–Ω–æ–π")
        lines.append("‚Ä¢ **–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ** –ø–æ —Å—Å—ã–ª–∫–µ –Ω–∏–∂–µ")
        lines.append("‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º —Å–≤–µ—Ä–∏—Ç—å —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏")

    # Add source link if available (for both AI and DB results)
    if source_url and source_url not in ['null', None, '', 'N/A']:
        # Format as Markdown link for cleaner appearance
        lines.append(f"\nüîó [–°—Å—ã–ª–∫–∞ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫]({source_url})")

    return '\n'.join(lines)


async def handle_button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle inline keyboard button callbacks"""
    query = update.callback_query
    await query.answer()

    # Parse callback data
    action, grade_name = query.data.split(':', 1)

    if action == 'confirm_ai':
        # User confirmed AI search
        await query.edit_message_text(
            f"‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ. –ó–∞–ø—É—Å–∫–∞—é AI Search –¥–ª—è –º–∞—Ä–∫–∏ `{grade_name}`...",
            parse_mode='Markdown'
        )

        # Reset attempt counter and perform AI search
        normalized_grade = grade_name.strip().upper()
        if normalized_grade in context.user_data.get('search_attempts', {}):
            del context.user_data['search_attempts'][normalized_grade]

        # Perform AI search
        # Create a fake update object for perform_ai_search
        class FakeMessage:
            def __init__(self, chat_id):
                self.chat_id = chat_id
                self.message_id = None

            async def reply_text(self, text, parse_mode=None):
                return await query.message.reply_text(text, parse_mode=parse_mode)

        fake_update = type('obj', (object,), {
            'message': FakeMessage(query.message.chat_id)
        })()

        await perform_ai_search(fake_update, grade_name, context)
        return

    elif action == 'retry_search':
        # User wants to try again - just inform them
        await query.edit_message_text(
            f"‚úèÔ∏è –•–æ—Ä–æ—à–æ, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.\n\n"
            f"–û—Ç–ø—Ä–∞–≤—å—Ç–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞—Ä–∫–∏ —Å—Ç–∞–ª–∏.",
            parse_mode='Markdown'
        )
        # Note: We don't reset the attempt counter - next search will be 3rd attempt (automatic AI)
        return

    elif action == 'add':
        # Get AI result from cache to add to database
        try:
            # Request API to get full result
            response = requests.get(
                f"{config.SEARCH_ENDPOINT}?grade={grade_name}&ai=true",
                timeout=10
            )

            if response.status_code == 200:
                results = response.json()
                if results and len(results) > 0:
                    result = results[0]

                    # Call API to add to database
                    add_response = requests.post(
                        f"{config.SEARCH_ENDPOINT.replace('/steels', '/steels/add')}",
                        json=result,
                        timeout=10
                    )

                    if add_response.status_code == 200:
                        await query.edit_message_text(
                            f"‚úÖ –ú–∞—Ä–∫–∞ `{grade_name}` –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö!",
                            parse_mode='Markdown'
                        )
                    else:
                        error = add_response.json().get('error', 'Unknown error')
                        await query.edit_message_text(
                            f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è: {error}",
                            parse_mode='Markdown'
                        )
                else:
                    await query.edit_message_text(
                        f"‚ùå –î–∞–Ω–Ω—ã–µ –¥–ª—è `{grade_name}` –Ω–µ –Ω–∞–π–¥–µ–Ω—ã",
                        parse_mode='Markdown'
                    )
            else:
                await query.edit_message_text(
                    f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {response.status_code}",
                    parse_mode='Markdown'
                )

        except Exception as e:
            await query.edit_message_text(
                f"‚ùå –û—à–∏–±–∫–∞: {str(e)}",
                parse_mode='Markdown'
            )

    elif action == 'del':
        # Delete from database
        try:
            response = requests.post(
                f"{config.SEARCH_ENDPOINT.replace('/steels', '/steels/delete')}",
                json={'grade': grade_name},
                timeout=10
            )

            if response.status_code == 200:
                await query.edit_message_text(
                    f"‚úÖ –ú–∞—Ä–∫–∞ `{grade_name}` —É–¥–∞–ª–µ–Ω–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö!",
                    parse_mode='Markdown'
                )
            else:
                error = response.json().get('error', 'Unknown error')
                await query.edit_message_text(
                    f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è: {error}",
                    parse_mode='Markdown'
                )

        except Exception as e:
            await query.edit_message_text(
                f"‚ùå –û—à–∏–±–∫–∞: {str(e)}",
                parse_mode='Markdown'
            )
